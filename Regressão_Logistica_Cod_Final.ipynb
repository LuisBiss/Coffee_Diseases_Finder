{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SU06j8EzxZIF"
   },
   "source": [
    "# Detecção de Doença em Folhas de Café com Regressão Logística\n",
    "\n",
    "Este projeto tem como objetivo classificar folhas de café como saudáveis ou doentes utilizando algoritmos de Machine Learning, com foco em Regressão Logística.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6950,
     "status": "ok",
     "timestamp": 1750637099609,
     "user": {
      "displayName": "Charles Junior",
      "userId": "13360980264868624638"
     },
     "user_tz": 180
    },
    "id": "YvOIcLnhxXsu"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '.venv (Python 3.10.11)' requires the ipykernel package.\n",
      "\u001b[1;31mInstall 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/Francisco/Desktop/Projetos/Coffee_Diseases_Finder/.venv/Scripts/python.exe -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# 1. Importações necessárias\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, learning_curve\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from google.colab import drive\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array, array_to_img\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 248,
     "status": "ok",
     "timestamp": 1750637143710,
     "user": {
      "displayName": "Charles Junior",
      "userId": "13360980264868624638"
     },
     "user_tz": 180
    },
    "id": "xK1-s4f8xj_m"
   },
   "outputs": [],
   "source": [
    "# 3. Configurações de caminhos\n",
    "base_path = \"/content/drive/MyDrive/coffee-leaf-dataset\"\n",
    "modelos_path = \"/content/drive/MyDrive/modelos\"\n",
    "os.makedirs(modelos_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 58,
     "status": "ok",
     "timestamp": 1750637145692,
     "user": {
      "displayName": "Charles Junior",
      "userId": "13360980264868624638"
     },
     "user_tz": 180
    },
    "id": "UDw64SgoxkKm"
   },
   "outputs": [],
   "source": [
    "# 4. Mapeamento de classes (0 = saudável, 1 = qualquer doença)\n",
    "label_map = {\n",
    "    \"Healthy\": 0,\n",
    "    \"Healthy_augmented\": 0,\n",
    "    \"Ferrugem\": 1,\n",
    "    \"Ferrugem_augmented\": 1,\n",
    "    \"Phoma\": 1,\n",
    "    \"Phoma_augmented\": 1,\n",
    "    \"Mineiro\": 1,\n",
    "    \"Mineiro_augmented\": 1,\n",
    "    \"Pulga_Vermelha\": 1,\n",
    "    \"Pulga_Vermelha_augmented\": 1,\n",
    "    \"Fosforo\": 1,\n",
    "    \"Fosforo_augmented\": 1\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 54,
     "status": "ok",
     "timestamp": 1750637148088,
     "user": {
      "displayName": "Charles Junior",
      "userId": "13360980264868624638"
     },
     "user_tz": 180
    },
    "id": "9yYjqS_UxkXe"
   },
   "outputs": [],
   "source": [
    "# 5. Função para aumentar imagens de todas as classes\n",
    "def augment_images(input_folder, output_folder, class_name):\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    img_size = (128, 128)\n",
    "    rotation_angles = [15, 30, 45, 60, 90, 120, 180]\n",
    "    flip_modes = ['horizontal', 'vertical', 'both']\n",
    "\n",
    "    for filename in os.listdir(input_folder):\n",
    "        if filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "            img_path = os.path.join(input_folder, filename)\n",
    "            img = load_img(img_path, target_size=img_size)\n",
    "            img_array = img_to_array(img)\n",
    "\n",
    "            # Rotação\n",
    "            for angle in rotation_angles:\n",
    "                rotated = tf.keras.preprocessing.image.random_rotation(\n",
    "                    img_array,\n",
    "                    rg=angle,\n",
    "                    row_axis=0,\n",
    "                    col_axis=1,\n",
    "                    channel_axis=2,\n",
    "                    fill_mode='nearest'\n",
    "                )\n",
    "                rotated_img = array_to_img(rotated)\n",
    "                new_filename = f\"{os.path.splitext(filename)[0]}_{class_name}_rot{angle}.jpg\"\n",
    "                rotated_img.save(os.path.join(output_folder, new_filename))\n",
    "\n",
    "            # Flip\n",
    "            for flip_mode in flip_modes:\n",
    "                if flip_mode == 'horizontal':\n",
    "                    flipped = np.fliplr(img_array)\n",
    "                elif flip_mode == 'vertical':\n",
    "                    flipped = np.flipud(img_array)\n",
    "                else:  # both\n",
    "                    flipped = np.flipud(np.fliplr(img_array))\n",
    "\n",
    "                flipped_img = array_to_img(flipped)\n",
    "                new_filename = f\"{os.path.splitext(filename)[0]}_{class_name}_flip{flip_mode}.jpg\"\n",
    "                flipped_img.save(os.path.join(output_folder, new_filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0QLM-Xnlxkvg"
   },
   "outputs": [],
   "source": [
    "# 6. Aumentar imagens para todas as classes\n",
    "for class_name in os.listdir(base_path):\n",
    "    class_path = os.path.join(base_path, class_name)\n",
    "    if os.path.isdir(class_path) and class_name in label_map and not class_name.endswith('_augmented'):\n",
    "        output_folder = os.path.join(base_path, f\"{class_name}_augmented\")\n",
    "        augment_images(class_path, output_folder, class_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1750635600709,
     "user": {
      "displayName": "Charles Junior",
      "userId": "13360980264868624638"
     },
     "user_tz": 180
    },
    "id": "OMQTWts7xk5I"
   },
   "outputs": [],
   "source": [
    "# 7. Função para carregar e preprocessar imagens\n",
    "def load_images(path, label_map, size=(128, 128)):\n",
    "    X, y = [], []\n",
    "    for folder in os.listdir(path):\n",
    "        folder_path = os.path.join(path, folder)\n",
    "        if not os.path.isdir(folder_path):\n",
    "            continue\n",
    "\n",
    "        # Determinar o nome da classe base (removendo '_augmented')\n",
    "        label_folder = folder.replace('_augmented', '')\n",
    "        if label_folder not in label_map:\n",
    "            continue\n",
    "\n",
    "        label = label_map[label_folder]\n",
    "        for img_file in os.listdir(folder_path):\n",
    "            img_path = os.path.join(folder_path, img_file)\n",
    "            img = cv2.imread(img_path)\n",
    "            if img is None:\n",
    "                continue\n",
    "\n",
    "            img = cv2.resize(img, size)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            X.append(img.flatten())\n",
    "            y.append(label)\n",
    "\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1147653,
     "status": "ok",
     "timestamp": 1750636753852,
     "user": {
      "displayName": "Charles Junior",
      "userId": "13360980264868624638"
     },
     "user_tz": 180
    },
    "id": "JEyzEJ6kxlE5",
    "outputId": "7711e666-c183-4259-aa23-be78c4f2a5e3"
   },
   "outputs": [],
   "source": [
    "# 8. Carregar dados\n",
    "X, y = load_images(base_path, label_map)\n",
    "print(f\"Total de amostras: {len(X)}\")\n",
    "print(f\"Tamanho de cada imagem (flattened): {X.shape[1]}\")\n",
    "\n",
    "# Verificar balanceamento de classes\n",
    "unique, counts = np.unique(y, return_counts=True)\n",
    "print(\"\\nDistribuição das classes:\")\n",
    "print(f\"Saudáveis (0): {counts[0]}\")\n",
    "print(f\"Doentes (1): {counts[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 193
    },
    "executionInfo": {
     "elapsed": 394,
     "status": "error",
     "timestamp": 1750637076753,
     "user": {
      "displayName": "Charles Junior",
      "userId": "13360980264868624638"
     },
     "user_tz": 180
    },
    "id": "qAOGqkkexlPd",
    "outputId": "7b51cda3-ed71-4cca-d1e6-f2cf64e2665e"
   },
   "outputs": [],
   "source": [
    "# 9. Normalização\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tQFVPCxpxlky"
   },
   "outputs": [],
   "source": [
    "# 10. Redução de dimensionalidade com PCA\n",
    "pca = PCA(n_components=100)\n",
    "X_pca = pca.fit_transform(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X7KVJbzRxlyX"
   },
   "outputs": [],
   "source": [
    "# 11. Divisão treino/teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_pca, y, test_size=0.2, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FzNd1jbIxl94"
   },
   "outputs": [],
   "source": [
    "# 12. Treinamento do modelo de regressão logística\n",
    "model = LogisticRegression(max_iter=3000, solver='saga', random_state=42)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n1S2rr6PxmLg"
   },
   "outputs": [],
   "source": [
    "# 13. Avaliação\n",
    "y_pred = model.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\nAcurácia: {acc:.2%}\")\n",
    "print(\"\\nRelatório de Classificação:\\n\", classification_report(y_test, y_pred, target_names=[\"Healthy\", \"Doente\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uwiS5arLxmiQ"
   },
   "outputs": [],
   "source": [
    "# 14. Matriz de Confusão\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=[\"Healthy\", \"Doente\"], yticklabels=[\"Healthy\", \"Doente\"])\n",
    "plt.xlabel('Predito')\n",
    "plt.ylabel('Real')\n",
    "plt.title('Matriz de Confusão')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "unNGRzzExmvO"
   },
   "outputs": [],
   "source": [
    "# 15. Avaliação treino/teste\n",
    "train_pred = model.predict(X_train)\n",
    "train_acc = accuracy_score(y_train, train_pred)\n",
    "print(f\"Acurácia no Treino: {train_acc:.2f}\")\n",
    "\n",
    "test_pred = model.predict(X_test)\n",
    "test_acc = accuracy_score(y_test, test_pred)\n",
    "print(f\"Acurácia no Teste: {test_acc:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PeKS6nP2xm8j"
   },
   "outputs": [],
   "source": [
    "# 16. Curva de Aprendizado\n",
    "train_sizes, train_scores, val_scores = learning_curve(\n",
    "    LogisticRegression(max_iter=3000, solver='saga'),\n",
    "    X_pca, y,\n",
    "    train_sizes=np.linspace(0.1, 1.0, 10),\n",
    "    cv=5,\n",
    "    scoring='accuracy'\n",
    ")\n",
    "\n",
    "train_mean = train_scores.mean(axis=1)\n",
    "val_mean = val_scores.mean(axis=1)\n",
    "\n",
    "plt.plot(train_sizes, train_mean, label='Treino')\n",
    "plt.plot(train_sizes, val_mean, label='Validação')\n",
    "plt.xlabel('Tamanho do conjunto de treino')\n",
    "plt.ylabel('Acurácia')\n",
    "plt.title('Curva de Aprendizado')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fll1k8zGxnIW"
   },
   "outputs": [],
   "source": [
    "# 17. Salvar modelo, scaler e PCA\n",
    "joblib.dump(model, os.path.join(modelos_path, 'modelo_logistico.pkl'))\n",
    "joblib.dump(scaler, os.path.join(modelos_path, 'scaler.pkl'))\n",
    "joblib.dump(pca, os.path.join(modelos_path, 'pca.pkl'))\n",
    "print(\"\\nModelo, scaler e PCA salvos com sucesso!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "shCBsSXIxndx"
   },
   "outputs": [],
   "source": [
    "# 18. Função para prever uma nova imagem\n",
    "def prever_imagem(imagem_path, modelo, scaler, pca, size=(128, 128)):\n",
    "    img = cv2.imread(imagem_path)\n",
    "    if img is None:\n",
    "        raise ValueError(\"Imagem não encontrada ou corrompida.\")\n",
    "\n",
    "    img = cv2.resize(img, size)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    img_flat = img.flatten().reshape(1, -1)\n",
    "\n",
    "    img_scaled = scaler.transform(img_flat)\n",
    "    img_pca = pca.transform(img_scaled)\n",
    "\n",
    "    pred = modelo.predict(img_pca)[0]\n",
    "    proba = modelo.predict_proba(img_pca)[0]\n",
    "\n",
    "    classe = \"Healthy\" if pred == 0 else \"Doente\"\n",
    "    confianca = proba[pred]\n",
    "\n",
    "    return classe, confianca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xj9yB6gcxn2i"
   },
   "outputs": [],
   "source": [
    "# 19. Exemplo de uso com uma imagem de teste\n",
    "image_test_path = \"/content/drive/MyDrive/imagem_teste/folha_exemplo.jpg\"\n",
    "\n",
    "# Carregar modelo salvo\n",
    "modelo_carregado = joblib.load(os.path.join(modelos_path, 'modelo_logistico.pkl'))\n",
    "scaler_carregado = joblib.load(os.path.join(modelos_path, 'scaler.pkl'))\n",
    "pca_carregado = joblib.load(os.path.join(modelos_path, 'pca.pkl'))\n",
    "\n",
    "# Fazer a previsão\n",
    "try:\n",
    "    classe, confianca = prever_imagem(image_test_path, modelo_carregado, scaler_carregado, pca_carregado)\n",
    "    print(f\"\\nPrevisão para a imagem de teste:\")\n",
    "    print(f\"Classe prevista: {classe}\")\n",
    "    print(f\"Confiança: {confianca:.2%}\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nErro ao processar a imagem de teste: {e}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyN2YnnKbTu739cS1Pf7qTa7",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
